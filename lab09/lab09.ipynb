{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac6eeb4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab09.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af9dc94",
   "metadata": {},
   "source": [
    "# CE 93: Lab Assignment 09\n",
    "\n",
    "You must submit the lab to Gradescope by the due date. You will submit the zip file produced by running the final cell of the assignment.\n",
    "\n",
    "## About this Lab\n",
    "The objective of this assignment is to perform hypothesis testing based on observed data.\n",
    "\n",
    "## Instructions \n",
    "**Run the first cell, Initialize Otter**, to import the autograder and submission exporter.\n",
    "\n",
    "Throughout the assignment, replace `...` with your answers. We use `...` as a placeholder and these should be deleted and replaced with your answers.\n",
    "\n",
    "Any part listed as a \"<font color='red'>**Question**</font>\" should be answered to receive credit.\n",
    "\n",
    "**Please save your work after every question!**\n",
    "\n",
    "To read the documentation on a Python function, you can type `help()` and add the function name between parentheses.\n",
    "\n",
    "**Run the cell below**, to import the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3463c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please run this cell, and do not modify the contents\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import statistics as stats\n",
    "import cmath\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import hashlib\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import FileUpload\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import os\n",
    "import resources\n",
    "import random                                  \n",
    "from statsmodels.stats.weightstats import ztest  \n",
    "from scipy.stats import * \n",
    "\n",
    "def get_hash(num):\n",
    "    \"\"\"Helper function for assessing correctness\"\"\"\n",
    "    return hashlib.md5(str(num).encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eac86e",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "For this week's lab, we will work with ammonia measurements across a river.\n",
    "\n",
    "Ammonia can be toxic to aquatic life at high levels. Typical natural sources of ammonia in water include: decomposition or breakdown of organic waste matter, gas exchange with the atmosphere, forest fires, animal and human waste, and nitrogen fixation processes. Some processes that directly create ammonia are commercial fertilizers and other industrial applications. When present at high levels, ammonia has a toxic effect on aquatic life. Because of this, it is important to monitor the ammonia levels in an aquatic environment.\n",
    "\n",
    "Source: https://www.epa.gov/wqc/aquatic-life-criteria-ammonia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b334f350",
   "metadata": {},
   "source": [
    "### Ammonia Data\n",
    "\n",
    "The California Environmental Protection Agency (CalEPA) is worried that the amount of ammonia in the environment is reaching unhealthy levels. Given your data analysis experience, they hired you as a consultant to analyze their data and better understand whether ammonia levels are unhealthy and what actions they should take.\n",
    "\n",
    "Let's load the provided data set `ammonia_conc.csv`. It has one feature, which is ammonia levels in ppm in the river of interest. There are a total of **150** measurements taken at random times over 1 year.\n",
    "\n",
    "|Feature|Units|\n",
    "|:-|:-|\n",
    "|Ammonia Level|ppm|\n",
    "\n",
    "* load using the Pandas `read_csv()` function\n",
    "\n",
    "The data are in units of **ppm** (parts per million). The unhealthy level is defined as **0.04 ppm**.\n",
    "\n",
    "Run the cell below, which reads the data and saves it as a variable named `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0844215",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read a .csv file as a DataFrame\n",
    "df = pd.read_csv('resources/ammonia_conc.csv')\n",
    "\n",
    "# returns the first 5 rows of the data set by default\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc38c0e-d4ad-44ce-b03a-aa96a6d87abc",
   "metadata": {},
   "source": [
    "### Create Variables from the DataFrame\n",
    "\n",
    "We want to generate a data vector for the ammonia level (easier to work with a data vector than a DataFrame)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41918ae-0ced-45bc-a64c-da7903273700",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color='red'>**Question 1.0.**</font> Create a data vector for the ammonia level and save it as variable `ammonia`. You can refer to previous labs to answer this question. (0.25 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ed1776-7a7a-4872-8e6b-7db75dcedea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ANSWER CELL\n",
    "# create variable for ammonia levels\n",
    "\n",
    "ammonia = ...\n",
    "\n",
    "print(ammonia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f77ac7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da2dbf7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color='red'>**Question 1.1.**</font> Compute the following summary statistics for `ammonia`. Do not just manually type the numeric answers. Use Python functions to determine the values. (1.25 pts)\n",
    "\n",
    "* What is the mean of ammonia? Assign your answer to `mean_ammonia`.\n",
    "* What is the median of ammonia? Assign your answer to `median_ammonia`.\n",
    "* What is the sample standard deviation of ammonia? Assign your answer to `stdev_ammonia`.\n",
    "* What is the coefficient of variation of nitrates? Compute this value as a decimal and not a percentage. Assign your answer to `cv_ammonia`.\n",
    "* What is the 95$^{th}$ percentile of ammonia? Assign your answer to `per_ammonia`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352f9138",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ANSWER CELL\n",
    "\n",
    "# compute summary statistics\n",
    "mean_ammonia = ...\n",
    "median_ammonia= ...\n",
    "stdev_ammonia = ...\n",
    "cv_ammonia = ...\n",
    "per_ammonia = ...\n",
    "\n",
    "print(f'Mean: {mean_ammonia:.4f} ppm' if not isinstance(mean_ammonia, type(Ellipsis)) else None)\n",
    "print(f'Median: {median_ammonia:.4f} ppm' if not isinstance(median_ammonia, type(Ellipsis)) else None)\n",
    "print(f'Standard deviation: {stdev_ammonia:.3f} ppm' if not isinstance(stdev_ammonia, type(Ellipsis)) else None)\n",
    "print(f'Coefficient of variation: {cv_ammonia:.3f}' if not isinstance(cv_ammonia, type(Ellipsis)) else None)\n",
    "print(f'95th percentile: {per_ammonia.round(3)} ppm' if not isinstance(per_ammonia, type(Ellipsis)) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d8e75a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a928432-e3ae-4dd4-bae8-4004bc8a6143",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color='red'>**Question 1.2.**</font> The unhealthy level for ammonia is defined as **0.040 ppm**. So, if the average **population** level is greater than 0.040 ppm, the water is considered unhealthy. Without performing any additional calculations, and based on the summary statistics above, can you conclude with **certainty** that the water is unhealthy?  Assign your answer to the variable `q1_2` as a string. (0.25 pts)\n",
    "\n",
    "**A.** Yes because the sample mean is greater than 0.04 ppm \\\n",
    "**B.** No because the sample mean is less than 0.04 ppm \\\n",
    "**C.** No because of sampling variation \\\n",
    "**D.** Yes because of sampling variation \\\n",
    "**E.** Yes because both the mean and median are greater than 0.04 ppm \\\n",
    "**F.** No because both the mean and median are less than 0.04 ppm\n",
    "\n",
    "Your answer should be a string, e.g., `\"A\"`, `\"B\"`, etc.\\\n",
    "Remember to put quotes around your answer choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daa7248",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ANSWER CELL\n",
    "q1_1 = ...\n",
    "q1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9417cb54",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ec6e0e-8263-4f31-be18-ee335c946a01",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "As with any sample, there is always sampling variation and uncertainty. It is important to recognize that a sample is influenced by measurement errors, sampling bias, sampling variation, among other factors. Therefore, to make conclusions on the population using data from uncertain and random samples, it is important to use proper statistical methods.\n",
    "\n",
    "For this data set, we are concerned that the population average ammonia levels are **greater** than the unhealthy level of 0.04 ppm. Therefore, our null and alternative hypotheses are as follows:\n",
    "\n",
    "**$H_0: \\mu = 0.040$ ppm**\n",
    "\n",
    "**$H_1: \\mu > 0.040$ ppm**\n",
    "\n",
    "where $\\mu$ is the population mean of ammonia levels\n",
    "\n",
    "Since we are interested in the population mean $\\mu$, we will use the sample mean $\\overline{X}$ as our test statistic to perform the hypothesis test.\n",
    "\n",
    "We have a large sample (150 measurements), and by the Central Limit Theorem, the sample mean, $\\overline{X}$, has a normal distribution, regardless of the underlying distribution of the population.\n",
    "\n",
    "The distribution of the test statistic under the null hypothesis is known as the **null** distribution. If the population standard deviation $\\sigma$ is unknown, it can be approximated by the sample standard deviation $s$ (for large samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb961156-0f34-4642-9ac4-c82b75ec254f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color='red'>**Question 2.0.**</font> What are the values of the parameters of the null distribution of the test statistic $\\overline{X}$ for the ammonia levels? Assign your answers to the variables `mu_null` and `sigma_null`. For `sigma_null`, do not just manually type the numeric answer. Use appropriate methods to determine the value. (0.5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3812415c-1e56-4e4b-8a68-44c57dab6dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ANSWER CELL\n",
    "\n",
    "# get parameters of the distribution of the test statistic\n",
    "mu_null = ...\n",
    "sigma_null = ...\n",
    "\n",
    "print(f'Null Distribution: N ({mu_null:.3f}, {sigma_null:.4f})' if not isinstance(mu_null, type(Ellipsis)) and not isinstance(sigma_null, type(Ellipsis)) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27b0f16",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aec27f-e864-48c7-858e-feee83c8b10b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color='red'>**Question 2.1.**</font> Under the null distribution (i.e., if $H_0$ were true), what is the $z$-score of the observed test statistic (i.e., of the observed sample mean)? Assign your answer to `z_score`. Do not just manually type the numeric answer. Use Python expressions that return the desired answer and assign the expression to the variable. (0.5 pts)\n",
    "\n",
    "The $z$-score of the test statistic is:\n",
    "\n",
    "$$z=\\dfrac{\\overline{x}-\\mu_0}{\\dfrac{\\sigma}{\\sqrt{n}}}$$\n",
    "\n",
    "where $\\mu_0$ is value of $\\mu$ under the null hypothesis\n",
    "\n",
    "If $\\sigma$ is unknown, it can be replaced  $s$ (for large samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05564c5-a392-484d-98c9-84e6a955ed11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ANSWER CELL\n",
    "\n",
    "z_score = ...\n",
    "\n",
    "print(f'Z-score: {z_score:.3f}' if not isinstance(z_score, type(Ellipsis)) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9074c159",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31998826-1b04-49ed-a946-5bd5d8b9c974",
   "metadata": {},
   "source": [
    "### $p$-value\n",
    "\n",
    "Now that you have obtained the $z$-score of the test statistic, you can compute the $p$-value. In the lecture, we defined the $p$-value as the probability of obtaining a test statistic at least as extreme as the result actually observed, assuming $H_0$ to be true (i.e., under the null distribution). In other words, it is the probability starting at the observed test statistic and looking in the direction(s) that support the alternative hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bc7616-a8f7-4a61-8839-e0e863ca7e32",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color='red'>**Question 2.2.**</font> Using $H_1: \\mu>0.04$ and the $z$-score of the test statistic you computed above, what is the $p$-value for this hypothesis test?\n",
    "\n",
    "*Hint:* P(Z < z) = $\\Phi(z)$ = `norm.cdf(z)`\n",
    "\n",
    "Assign your answer to `p_value`. Do not just manually type the numeric answer. Use Python expressions that return the desired answer and assign the expression to the variable. (0.5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ec7e1f-cbb6-429d-bc06-41e9faf21995",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ANSWER CELL\n",
    "\n",
    "p_value = ...\n",
    "\n",
    "print(f'p-value: {p_value:.3f}' if not isinstance(p_value, type(Ellipsis)) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04484779",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a864d2-2f8e-443d-8697-22ed1407efb4",
   "metadata": {},
   "source": [
    "### Decision\n",
    "\n",
    "The smaller the $p$-value, the stronger the evidence is against $H_0$. More specifically, if the $p$-value $\\leq$ the significance level $\\alpha$, the result is statistically significant at the $100\\alpha\\%$ level and we reject $H_0$. This is because a low $p$-value implies that it is very unlikely we observe a sample as extreme as our sample if $H_0$ were true.\n",
    "\n",
    "Otherwise, if the $p$-value $> \\alpha$, the result is not statistically significant at the $100\\alpha\\%$ level and we fail to reject $H_0$. This is because a $p$-value that is not low enough implies that it is not very unlikely we observe a sample as extreme as our sample if $H_0$ were true.\n",
    "\n",
    "The significance level $\\alpha$ is something that you, as a data analyst, should specify. It reflects the threshold probability that makes you \"feel comfortable\" rejecting $H_0$. A commonly used value is $\\alpha=0.05$, but other values are also used depending on the data being analyzed and how critical the analysis is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf1550f-7463-44c1-8c86-dcb9f85befe8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color='red'>**Question 2.3.**</font> What is the appropriate conclusion under the following significance levels? Assign ALL that apply to the variable `q2_3`. (1 pt)\n",
    "\n",
    "**A.** The result is statistically significant at the $\\underline{10\\%}$ level and we $\\underline{\\text{conclude}}$ that ammonia levels are unhealthy.\\\n",
    "**B.** The result is statistically significant at the $\\underline{5\\%}$ level and we $\\underline{\\text{conclude}}$ that ammonia levels are unhealthy. \\\n",
    "**C.** The result is statistically significant at the $\\underline{2\\%}$ level and we $\\underline{\\text{conclude}}$ that ammonia levels are unhealthy. \\\n",
    "**D.** The result is statistically significant at the $\\underline{1\\%}$ level and we $\\underline{\\text{conclude}}$ that ammonia levels are unhealthy. \\\n",
    "**E.** The result $\\underline{\\text{is not}}$ statistically significant at the $\\underline{10\\%}$ level and we $\\underline{\\text{can't conclude}}$ that ammonia levels are unhealthy.\\\n",
    "**F.** The result $\\underline{\\text{is not}}$ statistically significant at the $\\underline{5\\%}$ level and we $\\underline{\\text{can't conclude}}$ that ammonia levels are unhealthy.\\\n",
    "**G.** The result $\\underline{\\text{is not}}$ statistically significant at the $\\underline{2\\%}$ level and we $\\underline{\\text{can't conclude}}$ that ammonia levels are unhealthy.\\\n",
    "**H.** The result $\\underline{\\text{is not}}$ statistically significant at the $\\underline{1\\%}$ level and we $\\underline{\\text{can't conclude}}$ that ammonia levels are unhealthy.\n",
    "\n",
    "Answer in the next cell. Add each selected choice as a string and separate each two answer choices by a comma. For example, if you want to select `\"A\"` and `\"B\"`, your answer should be `\"A\", \"B\"`.\\\n",
    "Assign your answer to the given variable.\n",
    "Remember to put quotes around each answer choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbde61a0-b719-4467-b6c6-e98fdf933037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ANSWER CELL\n",
    "\n",
    "q2_3 = ...\n",
    "q2_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b004152e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6c19cf-0edd-4beb-8287-ea1250712065",
   "metadata": {},
   "source": [
    "### `ztest()` in `Python`\n",
    "\n",
    "We can easily perform all the steps you completed above in `Python` using a single line of code. When assuming a normal distribution for the test statistic and calculating a $z$-score (applicable when sample is large), the test is referred to as a $z$-test (because it is based on the $z$-distribution). \n",
    "\n",
    "When testing for the population mean, we can use: [`ztest(x1, value, alternative)`](https://www.statsmodels.org/stable/generated/statsmodels.stats.weightstats.ztest.html#statsmodels.stats.weightstats.ztest)\n",
    "\n",
    "* `x1` is the sample (all the sample values, not the sample mean)\n",
    "* `value` is the mean under the null hypothesis ($\\mu_0$)\n",
    "* `alternative` is the alternative hypothesis and takes on the following values:\n",
    "    1. `'two-sided'`: $H_1: \\mu \\neq \\mu_0$\n",
    "    2. `'larger'`: $H_1: \\mu > \\mu_0$\n",
    "    3. `'smaller'`: $H_1: \\mu < \\mu_0$\n",
    "\n",
    "So, if we want to test $H_1: \\mu < 1$, we can use: `ztest(ammonia, value=1, alternative='smaller')`. Note that we used `alternative='smaller'` because we are testing $H_1: \\mu < 1$. If we want to test a different alternative hypothesis, we have to update the parameter `alternative` accordingly.\n",
    "\n",
    "`ztest(x1, value, alternative)` returns a tuple with two values:\n",
    "1. The $z$-score of the test statistic\n",
    "2. The $p$-value\n",
    "\n",
    "We can extract these values (which is known as unpacking in Python) using:\n",
    "\n",
    "`z_score, p_value = ztest(x1, value, alternative)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bbcd3b-ff5c-4242-be31-8db2a21ed50b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color='red'>**Question 3.0.**</font> Using `ztest()` and $H_1: \\mu > 0.04$, confirm your answers to Questions 2.1 and 2.2. Specifically, what are the $z$-score and the $p$-value? Assign your answers to `z_score1` and `p_value1`, respectively. Do not just manually type the numeric answer. Use Python expressions that return the desired answer and assign the expression to the variable. (0.5 pts)\n",
    "\n",
    "Note that the values from `ztest()` and what you computed already should exactly match :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baf746f-ecc1-42ff-b1b4-f601e91c47b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ANSWER CELL\n",
    "\n",
    "z_score1, p_value1 = ...\n",
    "\n",
    "print(f'z-score: {z_score1:.3f}, p-value: {p_value1:.3f}' if not isinstance(z_score1, type(Ellipsis)) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c190e8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1ae8ee-abc4-4b68-9fae-e147df16cdc3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color='red'>**Question 3.1.**</font> Using `ztest()` and $H_1: \\mu \\neq 0.04$, what are the $z$-score and the $p$-value? Assign your answers to `z_score2` and `p_value2`, respectively. Do not just manually type the numeric answer. Use Python expressions that return the desired answer and assign the expression to the variable. (0.5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff185a31-cfeb-44c1-810c-5d0dbcc3652f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ANSWER CELL\n",
    "\n",
    "z_score2, p_value2 = ...\n",
    "\n",
    "print(f'z-score: {z_score2:.3f}, p-value: {p_value2:.3f}' if not isinstance(z_score2, type(Ellipsis)) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4e7f58",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d955b313-6748-4597-bec0-d3453c9ddfd5",
   "metadata": {},
   "source": [
    "### Small-Sample Test\n",
    "\n",
    "Everything we did thus far was based on a large sample. If the sample isn't large enough, we cannot assume a normal distribution for the test statistic. The only exception is if the underlying population is normal. In this case, we can use a $t$-distribution:\n",
    "\n",
    "$$\\dfrac{\\overline{X}-\\mu}{\\dfrac{s}{\\sqrt{n}}}\\sim t (df=n-1)$$\n",
    "\n",
    "Run the code below to select the last 10 ammonia measurements. This will be our small sample and we will save it as a new variable `ammonia_last`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2e0bf4-e449-4468-b1de-ba647a2c614b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run the code below to select the last 10 ammonia measurements.\n",
    "\n",
    "ammonia_last = ammonia[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62e197d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color='red'>**Question 4.0.**</font> Compute the sample mean of `ammonia_last` and assign it to `mean_ammonia_last`. Do not just manually type the numeric answer. Use Python expressions that return the desired answer and assign the expression to the variable. (0.25 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7d252d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ANSWER CELL\n",
    "\n",
    "# compute the mean of ammonia_last\n",
    "mean_ammonia_last = ...\n",
    "\n",
    "print(f'Sample mean of last 10 measurements: {mean_ammonia_last:.3f} ppm' if not isinstance(mean_ammonia_last, type(Ellipsis)) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d46f2e6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ce3542-3c5d-4309-ad11-c61c7101f28c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color='red'>**Question 4.1.**</font> Compare the mean of the subsample (`mean_ammonia_last`) to that of the full sample (`mean_ammonia`). What can you say based on this comparison? Assign ALL that apply to the variable `q4`. (0.5 pts)\n",
    "\n",
    "**A.** The mean of the subsample is greater than that of the full sample \\\n",
    "**B.** The mean of the subsample is equal to that of the full sample \\\n",
    "**C.** The mean of the subsample is smaller than that of the full sample \\\n",
    "**D.** Based on the mean values only, we can say that the subsample will have a lower **$p$**-value for testing $H_{1}: \\mu > 0.04$ than the full sample and thus stronger evidence against the null hypothesis \\\n",
    "**E.** Based on the mean values only, we can say that the subsample will have a higher **$p$**-value for testing $H_{1}: \\mu > 0.04$ than the full sample and thus weaker evidence against the null hypothesis \\\n",
    "**F.** We can't tell with certainty whether the subsample will have a lower **$p$**-value for testing $H_{1}: \\mu > 0.04$ than the full sample based on the mean values only because the null distribution will be different for the subsample\n",
    "\n",
    "Answer in the next cell. Add each selected choice as a string and separate each two answer choices by a comma. For example, if you want to select `\"A\"` and `\"B\"`, your answer should be `\"A\", \"B\"`.\\\n",
    "Assign your answer to the given variable.\n",
    "Remember to put quotes around each answer choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14690e5-e50d-4c3c-9022-52cf171df375",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ANSWER CELL\n",
    "\n",
    "q4 = ...\n",
    "q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47214687",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046ffbdb-3ac7-4f26-a624-6810b764b3f9",
   "metadata": {},
   "source": [
    "### `ttest_1samp()` in `Python`\n",
    "\n",
    "While you are very much capable of performing the hypothesis testing by computing the $t$-value of the test statistic and then the $p$-value (similar to what you did above), we will use existing `Python` functions to directly perform the hypothesis test. \n",
    "\n",
    "*Again, the reason we are using a $t$-distribution now is because our sample is small (n=10) and we are assuming that the underlying distribution in normal but with unknown population standard deviation $\\sigma$.*\n",
    "\n",
    "Assuming the underlying population is normal, we can perform hypothesis testing on the population mean using a $t$-statistic. The test is thus referred to as a $t$-test. Similar to `ztest()`, we can use: [`ttest_1samp(a, popmean, alternative)`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_1samp.html)\n",
    "\n",
    "* `a` is the observed sample\n",
    "* `popmean` is the mean under the null hypothesis, $\\mu_0$ **(this was called `value` for `ztest()`)**\n",
    "* `alternative` takes on the following values:\n",
    "    1. `'two-sided'`: $H_1: \\mu \\neq \\mu_0$\n",
    "    2. `'greater'`: $H_1: \\mu > \\mu_0$ **(this was called `'larger'` for `ztest()`)**\n",
    "    3. `'less'`: $H_1: \\mu < \\mu_0$ **(this was called `'smaller'` for `ztest()`)**\n",
    "    \n",
    "**Note that some of the parameters for `ttest_1samp()` use different names from `ztest()`.**\n",
    "\n",
    "So, if we want to test $H_1: \\mu < 1$, we can use: `ttest_1samp(ammonia_last, popmean=1, alternative='less')`. Note that we used `alternative='less'` because we are testing $H_1: \\mu < 1$. If we want to test a different alternative hypothesis, we have to update the parameter `alternative` accordingly.\n",
    "\n",
    "Similar to `ztest()`,  `ttest_1samp()` also returns a tuple with two values:\n",
    "1. The $z$-score of the test statistic\n",
    "2. The $p$-value\n",
    "\n",
    "We can extract these values (which is known as unpacking in Python) using:\n",
    "\n",
    "`t_score, p_value = ttest_1samp(a, popmean, alternative)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a488bdb6-1f1e-414b-905e-133f2dcc1885",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color='red'>**Question 5.0.**</font> Using `ttest_1samp()` and $H_1: \\mu > 0.04$ with `ammonia_last`, what are the $t$-score and the $p$-value? Assign your answers to `t_score` and `p_value3`, respectively. Do not just manually type the numeric answer. Use Python expressions that return the desired answer and assign the expression to the variable. (0.5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be30ff5-187d-4b87-83e4-17dd5ca21a38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ANSWER CELL\n",
    "\n",
    "t_score, p_value3 = ...\n",
    "\n",
    "print(f't-score: {t_score:.3f}, p-value: {p_value3:.3f}' if not isinstance(t_score, type(Ellipsis)) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e795cc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123fc7cf-aae3-4b0a-9183-9d2170dab859",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color='red'>**Question 5.1.**</font> What is the appropriate conclusion based on the $t$-test at the 0.05 significance level? Assign your answer to the variable `q5_1` as a string. (0.5 pts)\n",
    "\n",
    "**A.** The result $\\underline{\\text{is}}$ statistically significant at the $\\underline{5\\%}$ level and we $\\underline{\\text{conclude}}$ that ammonia levels are unhealthy. \\\n",
    "**B.** The result $\\underline{\\text{is not}}$ statistically significant at the $\\underline{5\\%}$ level and we $\\underline{\\text{conclude}}$ that ammonia levels are unhealthy. \\\n",
    "**C.** The result $\\underline{\\text{is}}$ statistically significant at the $\\underline{5\\%}$ level and we $\\underline{\\text{can't conclude}}$ that ammonia levels are unhealthy. \\\n",
    "**D.** The result $\\underline{\\text{is not}}$ statistically significant at the $\\underline{5\\%}$ level and we $\\underline{\\text{can't conclude}}$ that ammonia levels are unhealthy. \n",
    "\n",
    "Your answer should be a string, e.g., `\"A\"`, `\"B\"`, etc.\\\n",
    "Remember to put quotes around your answer choice.\n",
    "\n",
    "**Note that the test for this question will be a hidden test. Meaning, you will NOT be able to know whether your answer is correct or not by running the `grader.check()` cell. You should know how to confidently answer this question by now.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742dc326-4bf9-4097-9311-fb5f8cdef008",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ANSWER CELL\n",
    "\n",
    "q5_1 = ...\n",
    "q5_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c544e59",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4893ea1-040f-4d68-a0c4-0c34a66b0e57",
   "metadata": {},
   "source": [
    "If you did the calculations correctly, you should observe a higher $p$-value for the subsample than that of the full sample. But why?\n",
    "\n",
    "It is interesting to note the sample mean of `ammonia_last` is higher than that of the full sample. Thus, looking only at the sample means, one might be tempted to say that the subsample shows stronger evidence that $\\mu>0.040$ and thus stronger evidence against $H_0: \\mu=0.040$ (meaning, we should get a lower $p$-value).\n",
    "\n",
    "However, we obtained a higher $p$-value based on the subsample, indicating the opposite: a higher $p$-value implies that the sample is more likely if the null were true. The reason for this is that the small sample has much more uncertainty than the full sample (due to the smaller sample size), which results in more spread for the null distribution, and thus higher $p$-value in this case. The only way we could quantify this uncertainty and take it into consideration while making decisions is through proper statistical tests. That's why we perform hypothesis testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6b3b14-eb6e-47f2-a18d-1a7765fc17ce",
   "metadata": {},
   "source": [
    "### Small-Sample Test (Non-Normal Sample)\n",
    "\n",
    "In the lecture, we mentioned that when the population standard deviation is unknown and the sample size is small, the $t$-distribution is applicable **only if the population is normally distributed**. Just like estimating confidence intervals for non-normal distributions and small samples can be challenging, performing hypothesis testing for non-normal distributions and small samples can be challenging.\n",
    "\n",
    "In this case, we can perform hypothesis testing using bootstrapped confidence intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53f1a13-dc11-431e-b79f-62f944626ce7",
   "metadata": {},
   "source": [
    "### Bootstrapping \n",
    "\n",
    "Instead of using $p$-values to make decisions for hypothesis testing, we can calculate confidence intervals based on the sample and check if the null hypothesis falls within the confidence interval. If the null hypothesized value $H_0:\\mu=0.040$ is within the confidence interval, we fail to reject $H_0$.\n",
    "Otherwise, if the null hypothesized value $H_0:\\mu=0.040$ is not within the confidence interval, we reject $H_0$.\n",
    "\n",
    "In Lab 08, we saw how we can use bootstrapping to calculate confidence intervals for any estimate without making assumptions on the distribution of the data (or any assumptions at all!). \n",
    "\n",
    "Similarly, we can use bootstrapping to calculate confidence intervals and make decisions for hypothesis testing. If the significance level for hypothesis testing is $\\alpha$, the associated confidence interval is $100(1-\\alpha)\\%$.\n",
    "\n",
    "Let's select a total of **5000** bootstrap samples from `ammonia_last` and calculate the mean of each sample. Run the code cell below. Note that here we are specifying `random.seed(99)`, so the random sample will not change each time we rerun the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4b2cce-fb08-4f4f-9c6b-744917e066a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the random seed equal to 99\n",
    "random.seed(99)\n",
    "\n",
    "# specify the total number of samples to create\n",
    "n_samples = 5000\n",
    "\n",
    "# create an empty array to save the means of each sample\n",
    "bootstrap_means= []\n",
    "\n",
    "# loop through a total of n_samples times\n",
    "for i in range(n_samples):\n",
    "    \n",
    "    # select a random sample of the same size as the data and with replacement\n",
    "    bootstrapped_sample = random.choices(list(ammonia_last), k=len(ammonia_last))\n",
    "    \n",
    "    # calculate the sample mean\n",
    "    ammonia_sample_mean = np.mean(bootstrapped_sample)\n",
    "    \n",
    "    # append the mean value to save all the means\n",
    "    bootstrap_means = np.append(bootstrap_means, ammonia_sample_mean)\n",
    "    \n",
    "# print a few bootstrapped means\n",
    "print(f'Sample Bootstrapped Means: [{bootstrap_means[0]:.3f}, {bootstrap_means[1]:.3f}, ..., {bootstrap_means[-1]:.3f}] ppm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9564d463",
   "metadata": {},
   "source": [
    "Recall that our hypotheses are:\n",
    "\n",
    "**$H_0: \\mu = 0.040$ ppm**\n",
    "\n",
    "**$H_1: \\mu > 0.040$ ppm**\n",
    "\n",
    "To make a decision at the $\\alpha$ significance level using confidence intervals, we have to find an **appropriate** $100(1-\\alpha)\\%$ confidence interval. The confidence interval (two-sided, one-sided lower, or one-sided upper) should depend on the directionality of the alternative hypothesis. Refer to the lecture slides if you are unsure what to use in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811f1168-eb37-4392-8d03-764373b16570",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color='red'>**Question 6.0.**</font> Calculate the appropriate confidence interval for testing $H_1: \\mu > 0.040$ at the 0.05 significance level and plot the results along with the histogram of `bootstrap_means`. Follow these steps: (1.0 pt)\n",
    "\n",
    "1. Calculate the appropriate confidence interval for the mean. Assign the one-sided estimate of the confidence interval to `q6`.\n",
    "2. Plot a frequency histogram of `bootstrap_means` with `bins=15` and assign it to the variable `histogram`.\n",
    "3. Plot vertical a red line at the confidence interval bound extending from 0 to 1000. (refer to Lab 08)\n",
    "4. Plot the value of the null hypothesis $H_0: \\mu = 0.040$ using: `plt.scatter(0.04, 0, color='magenta', s=40, clip_on=False)`\n",
    "5. Set the x-axis label to `'Bootstrap Means (ppm)'` and the y-axis label to `'Frequency'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc65bac1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ANSWER CELL\n",
    "\n",
    "# Do not modify these lines for grading purposes\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "# create figure and axes\n",
    "fig_1, ax_1 = plt.subplots(nrows=1, ncols=1, figsize=(4,2.5))\n",
    "\n",
    "# Edit the code below to plot a frequency histogram of bootstrap_means (only edit where you have ...)\n",
    "\n",
    "# get the appropriate confidence interval\n",
    "q6 = ...\n",
    "\n",
    "# Plot frequency histogram. Assign the plot to the variable histogram.\n",
    "histogram = ...\n",
    "\n",
    "# plot red vertical line at the confidence interval estimate\n",
    "...\n",
    "\n",
    "# plot the value of the null hypothesis\n",
    "...\n",
    "\n",
    "# Label the axes\n",
    "...\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the interval\n",
    "print(f'Confidence interval for Mean using Bootstrapping: ({q6.round(4)}, infinity) ppm' if not isinstance(q6, type(Ellipsis)) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887d7d4d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957e346b-2056-4187-95d8-b913a64fe15e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color='red'>**Question 6.1.**</font> What is the appropriate conclusion based on the bootstrapped confidence interval? Assign ALL that apply to the variable `q6_1`. (0.5 pts)\n",
    "\n",
    "**A.** The confidence interval $\\underline{\\text{does not include}}$ the null hypothesized value.\\\n",
    "**B.** The confidence interval $\\underline{\\text{includes}}$ the null hypothesized value. \\\n",
    "**C.** The result $\\underline{\\text{is not}}$ statistically significant at the **5%** level and we $\\underline{\\text{conclude}}$ that ammonia levels are unhealthy. \\\n",
    "**D.** The result $\\underline{\\text{is}}$ statistically significant at the **5%** level and we $\\underline{\\text{conclude}}$ that ammonia levels are unhealthy. \\\n",
    "**E.** The result $\\underline{\\text{is}}$ statistically significant at the **5%** level and we $\\underline{\\text{can't conclude}}$ that ammonia levels are unhealthy.\\\n",
    "**F.** The result $\\underline{\\text{is not}}$ statistically significant at the **5%** level and we $\\underline{\\text{can't conclude}}$ that ammonia levels are unhealthy. \n",
    "\n",
    "\n",
    "Answer in the next cell. Add each selected choice as a string and separate each two answer choices by a comma. For example, if you want to select `\"A\"` and `\"B\"`, your answer should be `\"A\", \"B\"`.\\\n",
    "Assign your answer to the given variable.\n",
    "Remember to put quotes around each answer choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924b8f45-de02-40b7-b371-3002d94345de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ANSWER CELL\n",
    "\n",
    "q6_1 = ...\n",
    "q6_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac0ae65",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a662af7b-567b-42fd-9126-8748718666b4",
   "metadata": {},
   "source": [
    "## Difference in Means\n",
    "\n",
    "After doing more research, you find out that a nearby field has recently begun using a new fertilizer, which the CalEPA scientists suspect may be the source of increased ammonia concentration in the river. The last 10 ammonia measurements (which we saved as `ammonia_last`) were taken **after** the nearby field has begun using the new fertilizer. The **first 15** ammonia measurements were taken **before** the nearby field has begun using the new fertilizer. So, you are interested in testing if the mean ammonia amount has changed after the nearby field has begun using the new fertilizer. \n",
    "\n",
    "Run the code below to select the **first 15** ammonia measurements and save it as a new variable `ammonia_first`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea091fb-ed58-4179-8644-ef8c319f42cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the code below to select the first 15 ammonia measurements.\n",
    "\n",
    "ammonia_first = ammonia[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca901be-5a7e-4fcc-8ae5-084b070c7064",
   "metadata": {},
   "source": [
    "Let $\\mu_F$ be the average population ammonia levels before the nearby field has begun using the new fertilizer (corresponding sample is `ammonia_first`) and let $\\mu_L$ be the average population ammonia levels after the nearby field has begun using the new fertilizer (corresponding sample is `ammonia_last`). You are interested in testing whether the new fertilizer may be the source of increased ammonia concentration in the river, and thus, whether $\\mu_L>\\mu_F$. Therefore, our null and alternative hypotheses are as follows:\n",
    "\n",
    "Population means of ammonia levels are the same: **$H_0: \\mu_L = \\mu_F$**\n",
    "\n",
    "Population mean of ammonia levels has increased: **$H_1: \\mu_L > \\mu_F$**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c741f03d-428d-4dd9-8102-0ddad8fa95be",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color='red'>**Question 7.0.**</font> Based on the samples `ammonia_last` and `ammonia_first`, calculate a point estimate for $\\mu_L-\\mu_F$. Assign your answer to `mean_difference`. Do not just manually type the numeric answer. Use Python expressions that return the desired answer and assign the expression to the variable. (0.5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470f602d-1799-4a6c-af38-e1ab4433c0c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ANSWER CELL\n",
    "\n",
    "mean_difference = ...\n",
    "\n",
    "print(f'Point estimate for difference in means: {mean_difference:.3f} ppm' if not isinstance(mean_difference, type(Ellipsis)) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f3ca4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560599fd-83ed-49a2-b790-cd9c64f1a8f3",
   "metadata": {},
   "source": [
    "### Hypothesis Testing for Difference in Means\n",
    "\n",
    "Because both samples here are small (10 and 15 samples), we cannot use the central limit theorem to approximate the distribution of the sample means as normal. \n",
    "\n",
    "The only exception is if the underlying populations are normal. In this case, the distribution of the sample means would be a $t$-distribution and the distribution of the difference in means can also be approximated as a $t$-distribution. There are formulas to perform this hypothesis test on the difference in means from small samples, but we haven't covered them in this course.\n",
    "\n",
    "We will therefore use existing functions to perform the above hypothesis test for difference in means using small samples. We will use the following function: [`ttest_ind(a, b, equal_var, alternative)`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html#scipy.stats.ttest_ind)\n",
    "\n",
    "* `a` is the first observed sample\n",
    "* `b` is the second observed sample\n",
    "* `equal_var`: if `True` (default), the test assumes equal population variances for the two populations from which `a` and `b` were sampled. If `False`, the test does not assume equal population variances for the two populations from which `a` and `b` were sampled. The best practice is to assume the variances to be unequal unless we have reasons to believe that they are equal. So, it is recommended to set `equal_var = False`.\n",
    "* `alternative` takes on the following values:\n",
    "    1. `'two-sided'`: $H_1: \\mu_a \\neq \\mu_b$\n",
    "    2. `'greater'`: $H_1: \\mu_a > \\mu_b$\n",
    "    3. `'less'`: $H_1: \\mu_a < \\mu_b$\n",
    "\n",
    "**Note that the order of the samples, `a` and `b` is important for one-sided tests. If you use `altenrative='greater'`, the test will be performed for $H_1: \\mu_a > \\mu_b$, where $\\mu_a$ is the population mean corresponding to the first input, `a`, and $\\mu_b$ is the population mean corresponding to the second input, `b`.**\n",
    "\n",
    "So, if we want to test $H_1: \\mu_L \\neq \\mu_F$, we can use: `ttest_ind(ammonia_last, ammonia_first, equal_var=False, alternative='two-sided')`. Note that we used `alternative='two-sided'` because we are testing $H_1: \\mu_L \\neq \\mu_F$. If we want to test a different alternative hypothesis, we have to update the parameter `alternative` accordingly.\n",
    "\n",
    "The test requires that the two samples `a` and `b` be independent.\n",
    "\n",
    "Similar to other hypothesis testing functions, `ttest_ind()` also returns a tuple with two values:\n",
    "1. The $z$-score of the test statistic\n",
    "2. The $p$-value\n",
    "\n",
    "We can extract these values (which is known as unpacking in Python) using:\n",
    "\n",
    "`t_score, p_value = ttest_ind(a, b, equal_var, alternative)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044a4cdd-00e1-4447-8085-a3c3676f5756",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color='red'>**Question 7.1.**</font> Using `ttest_ind()` and **$H_1: \\mu_L > \\mu_F$**, what are the $t$-score and the $p$-value? Assign your answers to `t_score2` and `p_value4`, respectively. Assume that the samples are independent and that their populations **do not have equal variance**. Do not just manually type the numeric answer. Use Python expressions that return the desired answer and assign the expression to the variable. (0.5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd88e78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ANSWER CELL\n",
    "\n",
    "t_score2, p_value4 = ...\n",
    "\n",
    "print(f't-score: {t_score2:.3f}, p-value: {p_value4:.3f}' if not isinstance(t_score2, type(Ellipsis)) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408c8e43",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1b9793-1801-4cf3-a079-89e894e8bcbc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color='red'>**Question 7.2.**</font> What is the appropriate conclusion based on the two-sample $t$-test at the 0.05 significance level? Assign your answer to the variable `q7_2` as a string. (0.5 pts)\n",
    "\n",
    "**A.** The result $\\underline{\\text{is}}$ statistaclly significant at the **5%** level and we $\\underline{\\text{conclude}}$ that ammonia levels increased after using the new fertilizer.\\\n",
    "**B.** The result $\\underline{\\text{is}}$ statistaclly significant at the **5%** level and we $\\underline{\\text{can't conclude}}$ that ammonia levels increased after using the new fertilizer. \\\n",
    "**C.** The result $\\underline{\\text{is not}}$ statistaclly significant at the **5%** level and we $\\underline{\\text{conclude}}$ that ammonia levels increased after using the new fertilizer. \\\n",
    "**D.** The result $\\underline{\\text{is not}}$ statistaclly significant at the **5%** level and we $\\underline{\\text{can't conclude}}$ that ammonia levels increased after using the new fertilizer. \n",
    "\n",
    "Your answer should be a string, e.g., `\"A\"`, `\"B\"`, etc.\\\n",
    "Remember to put quotes around your answer choice.\n",
    "\n",
    "**Note that the test for this question will be a hidden test. Meaning, you will NOT be able to know whether your answer is correct or not by running the `grader.check()` cell. You should know how to confidently answer this question by now.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c13f5f6-2712-4cd5-a113-3f35ef8db67e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ANSWER CELL\n",
    "q7_2 = ...\n",
    "q7_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16da016d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85af3f62-7bfa-4e3f-be81-838656d7dbb9",
   "metadata": {},
   "source": [
    "## Extra: Bootstrapping Difference in Means\n",
    "\n",
    "As previously mentioned, $t$-tests require that the underlying population be normal, which is not always true. In this case we can perform bootstrapping to get confidence intervals and reach a conclusion for the hypothesis testing. Our hypotheses are: \n",
    "\n",
    "Population means of ammonia levels are the same: **$H_0: \\mu_L = \\mu_F$**\n",
    "\n",
    "Population means of ammonia levels increased: **$H_1: \\mu_L > \\mu_F$**\n",
    "\n",
    "We can re-write them as follows:\n",
    "\n",
    "**$H_0: \\mu_L - \\mu_F =0 $**\n",
    "\n",
    "**$H_1: \\mu_L - \\mu_F >0$**\n",
    "\n",
    "To perform the test without assuming the populations are normal, we can select a bootstrap sample from `ammonia_last` and another bootstrap sample from `ammonia_first`. We can then compute the difference of the means of the bootstrapped samples, and this would be one sample for $\\mu_L - \\mu_F$. If we repeat this 5000 times, we will get 5000 bootstrapped samples for the difference in means. Then, we can compute the appropriate confidence interval for $\\mu_L - \\mu_F$ based on $\\alpha$ and the alternative hypothesis. Finally, if the value $\\mu_L - \\mu_F =0 $ is within the bootstrapped difference in means, we fail to reject $H_0$.\n",
    "Otherwise, if the null hypothesized value is not within the confidence interval, we reject $H_0$.\n",
    "\n",
    "The beauty of this is that we don't have to make any assumptions on the distributions or whether the populations have equal variances, or any other assumptions.\n",
    "\n",
    "Read then run the code below, which implements the steps above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e804743-e8d1-4955-93b5-daf9f2c58361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the random seed equal to 99\n",
    "random.seed(99)\n",
    "\n",
    "# create figure and axes\n",
    "fig_2, ax_2 = plt.subplots(nrows=1, ncols=1, figsize=(4,2.5))\n",
    "\n",
    "# specify the total number of samples to create\n",
    "n_samples = 5000\n",
    "\n",
    "# create an empty array to save the difference in means\n",
    "bootstrap_means_diff= []\n",
    "\n",
    "# loop through a total of n_samples times\n",
    "for i in range(n_samples):\n",
    "    \n",
    "    # select a random sample of the same size as the data and with replacement from ammonia_last\n",
    "    bootstrapped_sample_last = random.choices(list(ammonia_last), k=len(ammonia_last))\n",
    "    \n",
    "    # select a random sample of the same size as the data and with replacement from ammonia_first\n",
    "    bootstrapped_sample_first = random.choices(list(ammonia_first), k=len(ammonia_first))\n",
    "    \n",
    "    # calculate the difference in sample means\n",
    "    ammonia_sample_mean_diff = np.mean(bootstrapped_sample_last)-np.mean(bootstrapped_sample_first)\n",
    "    \n",
    "    # append the difference in sample means\n",
    "    bootstrap_means_diff = np.append(bootstrap_means_diff, ammonia_sample_mean_diff)\n",
    "\n",
    "# get the 5th percentile of the bootstrapped difference in means\n",
    "# Because H1 has a \">\" sign, the appropriate confidence interval is: (low, infinity)\n",
    "# So, we only need one value for the confidence interval\n",
    "# for alpha = 0.05, this would be a 95% lower-confidence interval\n",
    "# Thus, we want the 5th percentile of the bootstrapped values\n",
    "low = np.percentile(bootstrap_means_diff, 5)\n",
    "\n",
    "# divide bootsrapped values into two groups: one within CI and one outside CI\n",
    "bootstrap_means_diff_within = bootstrap_means_diff[bootstrap_means_diff>low] # CI is (low, infinity)\n",
    "bootstrap_means_diff_outside = bootstrap_means_diff[bootstrap_means_diff<low]\n",
    "\n",
    "# plot a histogram of the bootstrapped means\n",
    "plt.hist(bootstrap_means_diff_within, bins=11, color='g', ec='k') # plot those within CI in green\n",
    "plt.hist(bootstrap_means_diff_outside, bins=5, color='m', ec='k') # plot those outside CI in magenta\n",
    "\n",
    "# plot magenta vertical lines at the 5th percentile, which is the cutoff for the CI\n",
    "plt.vlines(low, 0, 1000, 'm', ':', lw=2)\n",
    "\n",
    "# plot the null hypothesis value using  a blue dot\n",
    "plt.scatter(0.0, 0, color='blue', s=40, clip_on=False)\n",
    "\n",
    "# specify y limits\n",
    "plt.ylim(0, 1000)\n",
    "\n",
    "# label axes\n",
    "plt.xlabel('Difference in Means, $\\mu_L-\\mu_F$ (ppm)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# display plot\n",
    "plt.show()\n",
    "\n",
    "# Print the interval\n",
    "print('Bootsrtapped 95% CI: (' + str(np.round(low,3)) + ', infinity)')\n",
    "\n",
    "# Print decision\n",
    "print('Null Hypothesis is not within CI: Reject H0') if 0<low else print('Null Hypothesis is within CI: Fail to reject H0')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c62b677-226e-426c-9383-8d12fd5e48bb",
   "metadata": {},
   "source": [
    "The histogram shows all the bootstrapped values for the difference in means (total of 5000 values). The dotted vertical magenta line corresponds to the cutoff value for the confidence interval. Because this is a one-sided test with an alternative hypothesis having $>$ sign, the appropriate confidence interval should be one-sided with also the form $>$ some cutoff value. The bootstrapped values are thus divided into two groups:\n",
    "1. Those in green are within the confidence interval (upper 95% of the bootstrapped means)\n",
    "2. Those in magenta are outside the confidence interval (lower 5% of the bootstrapped means)\n",
    "\n",
    "Then shown using the blue dot is the null hypothesized value $\\mu_L - \\mu_F =0 $. We can see that for the 0.05 significance level, the blue dot falls outside the confidence interval, and thus, we reject the null hypothesis and conclude that the mean amount of ammonia increased after using the new fertilizer: $\\mu_L>\\mu_F$.\n",
    "\n",
    "You don't have to answer any questions for this last part :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20bba6f",
   "metadata": {},
   "source": [
    "### You're done with this Lab!\n",
    "\n",
    "**Important submission information:** After completing the assignment, click on the Save icon from the Tool Bar &nbsp;<i class=\"fa fa-save\" style=\"font-size:16px;\"></i>&nbsp;. After saving your notebook, **run the cell with** `grader.check_all()` and confirm that you pass the same tests as in the notebook. Then, **run the final cell** `grader.export()` and click the link to download the zip file. Finally, go to Gradescope and submit the zip file to the corresponding assignment. \n",
    "\n",
    "**Once you have submitted, stay on the Gradescope page to confirm that you pass the same tests as in the notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1647c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "img = mpimg.imread('resources/animal.jpg')\n",
    "imgplot = plt.imshow(img)\n",
    "imgplot.axes.get_xaxis().set_visible(False)\n",
    "imgplot.axes.get_yaxis().set_visible(False)\n",
    "print(\"Congratulations on finishing this lab!\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37617844",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb61c20",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acef3a74",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Make sure you submit the .zip file to Gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2703e3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab7e761",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "lab09",
   "tests": {
    "q1.0": {
     "name": "q1.0",
     "points": 0.25,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(len(ammonia)) == '7ef605fc8dba5425d6965fbd4c8fbe1f'\n>>> assert get_hash(sum(ammonia)) == 'b1d16c12de172122839ce255dba9f79d'\n",
         "failure_message": "Incorrect ammonia.",
         "hidden": false,
         "locked": false,
         "points": 0.25
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.1": {
     "name": "q1.1",
     "points": 1.25,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(round(mean_ammonia, 10)) == 'f2f75c76c58203a0f9e21e263c02e8fd'\n",
         "failure_message": "Incorrect mean.",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> assert get_hash(round(median_ammonia, 10)) == '8c310c0054514ba19515095665d1edb5'\n",
         "failure_message": "Incorrect median.",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> assert get_hash(round(stdev_ammonia, 10)) == '98095ea063763daedfd2a14815dd06fa'\n",
         "failure_message": "Incorrect standard deviation. If using np.std(), you need to specify ddof=1.",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> assert get_hash(round(cv_ammonia, 10)) == 'e925f3e79bbfa49876e2a9e98fa0ec28'\n",
         "failure_message": "Incorrect coefficient of variation. Recall that coefficient of variation is standard deviation / mean. Also, report it as a decimal, not percentage.",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> if isinstance(per_ammonia, np.ndarray):\n...     assert get_hash(per_ammonia.round(10)) == 'd21123ecddb5b2b5a634f7a0b5ed72a2'\n... else:\n...     assert get_hash(per_ammonia.round(10)) == '704385c0bed13024abc9664c6af0d8bf'\n",
         "failure_message": "Incorrect percentile. You can use the np.percentile() function.",
         "hidden": false,
         "locked": false,
         "points": 0.25
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.2": {
     "name": "q1.2",
     "points": 0.25,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(q1_1) == 1\n>>> assert isinstance(q1_1, str)\n",
         "failure_message": "Incorrect answer format. Make sure you only have the letter of your answer choice in quotes.",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Correct answer format."
        },
        {
         "code": ">>> assert get_hash(q1_1.upper()) == '0d61f8370cad1d412f80b84d143e1257'\n",
         "failure_message": "Incorrect answer.",
         "hidden": false,
         "locked": false,
         "points": 0.25
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.0": {
     "name": "q2.0",
     "points": 0.5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(round(mu_null, 10)) == 'e38502749f773d33ee02de5c2f61d6f3'\n",
         "failure_message": "Incorrect mean. What is the expected value of the sample mean? What is it equal to under the null dsitribution?",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> assert get_hash(round(sigma_null, 10)) == '023451c8f9115bed195e44ec1ed9a366'\n",
         "failure_message": "Incorrect sigma. What is the standard deviation of the sample mean? It is not the same as the sample standard deviation.",
         "hidden": false,
         "locked": false,
         "points": 0.25
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.1": {
     "name": "q2.1",
     "points": 0.5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(round(z_score, 10)) == 'f4aee4ca9327828e98de08d2ee66f723'\n",
         "failure_message": "Incorrect answer.",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.2": {
     "name": "q2.2",
     "points": 0.5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(round(p_value, 10)) == '56969a29f9835c7cb66aaf46e6294393'\n",
         "failure_message": "Incorrect answer. The alternative has a > sign. Also, do not manually type the value of z. Use the corresponding variable name.",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.3": {
     "name": "q2.3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(q2_3, (tuple, str))\n>>> assert all((isinstance(option, str) for option in q2_3))\n>>> assert all((len(option) == 1 for option in q2_3))\n",
         "failure_message": "Incorrect answer format. Make sure you only have the letter of your answer choice in quotes and answers are separated by commas.",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Correct answer format."
        },
        {
         "code": ">>> assert not any(('3a3ea00cfc35332cedf6e5e9a32e94da' == get_hash(option.upper()) for option in q2_3))\n",
         "failure_message": "Incorrect answer. Is the p-value less than 10%?",
         "hidden": false,
         "locked": false,
         "points": 0.1
        },
        {
         "code": ">>> assert not any(('800618943025315f869e4e1f09471012' == get_hash(option.upper()) for option in q2_3))\n",
         "failure_message": "Incorrect answer. Is the p-value less than 5%?",
         "hidden": false,
         "locked": false,
         "points": 0.1
        },
        {
         "code": ">>> assert not any(('dfcf28d0734569a6a693bc8194de62bf' == get_hash(option.upper()) for option in q2_3))\n",
         "failure_message": "Incorrect answer. Is the p-value less than 2%?",
         "hidden": false,
         "locked": false,
         "points": 0.1
        },
        {
         "code": ">>> assert any(('c1d9f50f86825a1a2302ec2449c17196' == get_hash(option.upper()) for option in q2_3))\n",
         "failure_message": "Incorrect answer. Is the p-value less than 1%?",
         "hidden": false,
         "locked": false,
         "points": 0.15
        },
        {
         "code": ">>> assert any(('7fc56270e7a70fa81a5935b72eacbe29' == get_hash(option.upper()) for option in q2_3))\n",
         "failure_message": "Incorrect answer. Is the p-value less than 10%?",
         "hidden": false,
         "locked": false,
         "points": 0.15
        },
        {
         "code": ">>> assert any(('9d5ed678fe57bcca610140957afab571' == get_hash(option.upper()) for option in q2_3))\n",
         "failure_message": "Incorrect answer. Is the p-value less than 5%?",
         "hidden": false,
         "locked": false,
         "points": 0.15
        },
        {
         "code": ">>> assert any(('0d61f8370cad1d412f80b84d143e1257' == get_hash(option.upper()) for option in q2_3))\n",
         "failure_message": "Incorrect answer. Is the p-value less than 2%?",
         "hidden": false,
         "locked": false,
         "points": 0.15
        },
        {
         "code": ">>> assert not any(('f623e75af30e62bbd73d6df5b50bb7b5' == get_hash(option.upper()) for option in q2_3))\n",
         "failure_message": "Incorrect answer. Is the p-value less than 1%?",
         "hidden": false,
         "locked": false,
         "points": 0.1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": 0.5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(round(z_score1, 10)) == 'f4aee4ca9327828e98de08d2ee66f723'\n>>> assert get_hash(round(p_value1, 10)) == '56969a29f9835c7cb66aaf46e6294393'\n",
         "failure_message": "Incorrect answer.",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.1": {
     "name": "q3.1",
     "points": 0.5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(round(z_score2, 10)) == 'f4aee4ca9327828e98de08d2ee66f723'\n>>> assert get_hash(round(p_value2, 10)) == 'ebeb978191ddb327c743f77bf002a718'\n",
         "failure_message": "Incorrect answer. The alternative is different for this question.",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4.0": {
     "name": "q4.0",
     "points": 0.25,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(round(mean_ammonia_last, 10)) == 'ff526d0d3b8baa3f08b5046721d2fd62'\n",
         "failure_message": "Incorrect answer.",
         "hidden": false,
         "locked": false,
         "points": 0.25
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4.1": {
     "name": "q4.1",
     "points": 0.5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(q4, (tuple, str))\n>>> assert all((isinstance(option, str) for option in q4))\n>>> assert all((len(option) == 1 for option in q4))\n",
         "failure_message": "Incorrect answer format. Make sure you only have the letter of your answer choice in quotes and answers are separated by commas.",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Correct answer format."
        },
        {
         "code": ">>> assert not any(('f623e75af30e62bbd73d6df5b50bb7b5' == get_hash(option.upper()) for option in q4))\n",
         "failure_message": "Incorrect answer. Will the null distribution change if the sample size changes?",
         "hidden": false,
         "locked": false,
         "points": 0.05
        },
        {
         "code": ">>> assert not any(('3a3ea00cfc35332cedf6e5e9a32e94da' == get_hash(option.upper()) for option in q4))\n",
         "failure_message": "Incorrect answer. Will the null distribution change if the sample size changes?",
         "hidden": false,
         "locked": false,
         "points": 0.05
        },
        {
         "code": ">>> assert any(('800618943025315f869e4e1f09471012' == get_hash(option.upper()) for option in q4))\n",
         "failure_message": "Incorrect answer. Will the null distribution change if the sample size changes?",
         "hidden": false,
         "locked": false,
         "points": 0.15
        },
        {
         "code": ">>> assert any(('7fc56270e7a70fa81a5935b72eacbe29' == get_hash(option.upper()) for option in q4))\n",
         "failure_message": "Incorrect answer.",
         "hidden": false,
         "locked": false,
         "points": 0.15
        },
        {
         "code": ">>> assert not any(('9d5ed678fe57bcca610140957afab571' == get_hash(option.upper()) for option in q4))\n",
         "failure_message": "Incorrect answer.",
         "hidden": false,
         "locked": false,
         "points": 0.05
        },
        {
         "code": ">>> assert not any(('0d61f8370cad1d412f80b84d143e1257' == get_hash(option.upper()) for option in q4))\n",
         "failure_message": "Incorrect answer.",
         "hidden": false,
         "locked": false,
         "points": 0.05
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5.0": {
     "name": "q5.0",
     "points": 0.5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(round(t_score, 10)) == '8c2dcb9224a2ab6a176772a5b42efdb8'\n>>> assert get_hash(round(p_value3, 10)) == 'aedd27162fcec476d10ac0c9bb6e8919'\n",
         "failure_message": "Incorrect answer.",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5.1": {
     "name": "q5.1",
     "points": 0.5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(q5_1) == 1\n>>> assert isinstance(q5_1, str)\n",
         "failure_message": "Incorrect answer format. Make sure you only have the letter of your answer choice in quotes.",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Correct answer format. Note that the actual test is hidden."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6.0": {
     "name": "q6.0",
     "points": 1.0,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert type(fig_1).__name__ == 'Figure'\n>>> assert type(ax_1).__name__ == 'Axes'\n",
         "failure_message": "Make sure to create a figure with 1 axes and assign them to \"fig_1\" and \"ax_1\".",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> assert get_hash(round(q6, 10)) == 'bc3be7dbdba51d85c35fca379529fc31'\n",
         "failure_message": "Incorrect answer for the confidence interval.",
         "hidden": false,
         "locked": false,
         "points": 0.4
        },
        {
         "code": ">>> assert isinstance(histogram, tuple)\n>>> assert len(histogram) == 3\n",
         "failure_message": "Make sure to save the histogram as object \"histogram\".",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> assert get_hash(len(histogram[0])) == '9bf31c7ff062936a96d3c8bd1f8f2ff3'\n>>> assert get_hash(len(histogram[1])) == 'c74d97b01eae257e44aa9d5bade97baf'\n>>> assert get_hash(sum(histogram[0])) == '9ca518dc0b3789adb8ad93efa4978101'\n>>> assert get_hash(sum(histogram[1])) == 'ae8f3b0a302010ca25a78c5ad0105549'\n",
         "failure_message": "Incorrect values plotted.",
         "hidden": false,
         "locked": false,
         "points": 0.4
        },
        {
         "code": ">>> assert isinstance(ax_1.collections[0], LineCollection)\n",
         "failure_message": "Make sure you are plotting the confidence interval estimates to ax_1 using vlines().",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> assert round(ax_1.collections[0].get_segments()[0][0, 0], 3) == round(q6, 3)\n>>> assert round(ax_1.collections[0].get_segments()[0][0, 1], 3) == round(0, 3)\n>>> assert round(ax_1.collections[0].get_segments()[0][1, 1], 3) >= round(1000, 3)\n",
         "failure_message": "Check the plotted vertical lines. They should extend between 0 and 1500.",
         "hidden": false,
         "locked": false,
         "points": 0.1
        },
        {
         "code": ">>> keywords = ['BOOTSTRAP', 'MEANS', 'PPM']\n>>> assert all((word in ax_1.get_xlabel().upper() for word in keywords))\n",
         "failure_message": "Check x-axis label.",
         "hidden": false,
         "locked": false,
         "points": 0.05
        },
        {
         "code": ">>> keywords = ['FREQUENCY']\n>>> assert all((word in ax_1.get_ylabel().upper() for word in keywords))\n",
         "failure_message": "Check y-axis label.",
         "hidden": false,
         "locked": false,
         "points": 0.05
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6.1": {
     "name": "q6.1",
     "points": 0.5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(q6_1, (tuple, str))\n>>> assert all((isinstance(option, str) for option in q6_1))\n>>> assert all((len(option) == 1 for option in q6_1))\n",
         "failure_message": "Incorrect answer format. Make sure you only have the letter of your answer choice in quotes and answers are separated by commas.",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Correct answer format."
        },
        {
         "code": ">>> assert any(('7fc56270e7a70fa81a5935b72eacbe29' == get_hash(option.upper()) for option in q6_1))\n",
         "failure_message": "Incorrect answer.",
         "hidden": false,
         "locked": false,
         "points": 0.15
        },
        {
         "code": ">>> assert not any(('9d5ed678fe57bcca610140957afab571' == get_hash(option.upper()) for option in q6_1))\n",
         "failure_message": "Incorrect answer.",
         "hidden": false,
         "locked": false,
         "points": 0.05
        },
        {
         "code": ">>> assert not any(('0d61f8370cad1d412f80b84d143e1257' == get_hash(option.upper()) for option in q6_1))\n",
         "failure_message": "Incorrect answer.",
         "hidden": false,
         "locked": false,
         "points": 0.05
        },
        {
         "code": ">>> assert any(('f623e75af30e62bbd73d6df5b50bb7b5' == get_hash(option.upper()) for option in q6_1))\n",
         "failure_message": "Incorrect answer.",
         "hidden": false,
         "locked": false,
         "points": 0.15
        },
        {
         "code": ">>> assert not any(('3a3ea00cfc35332cedf6e5e9a32e94da' == get_hash(option.upper()) for option in q6_1))\n",
         "failure_message": "Incorrect answer.",
         "hidden": false,
         "locked": false,
         "points": 0.05
        },
        {
         "code": ">>> assert not any(('800618943025315f869e4e1f09471012' == get_hash(option.upper()) for option in q6_1))\n",
         "failure_message": "Incorrect answer.",
         "hidden": false,
         "locked": false,
         "points": 0.05
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7.0": {
     "name": "q7.0",
     "points": 0.5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(round(mean_difference, 10)) == '80e457185a7310aacd93f4fa1ddc6a73'\n",
         "failure_message": "Incorrect answer.",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7.1": {
     "name": "q7.1",
     "points": 0.5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_hash(round(t_score2, 10)) == 'b702d016af456c255fcad167ec459429'\n>>> assert get_hash(round(p_value4, 10)) == 'db946baa40f0eb87ab5d7558859996f8'\n",
         "failure_message": "Incorrect answer.",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7.2": {
     "name": "q7.2",
     "points": 0.5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(q7_2) == 1\n>>> assert isinstance(q7_2, str)\n",
         "failure_message": "Incorrect answer format. Make sure you only have the letter of your answer choice in quotes.",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Correct answer format. Note that the actual test is hidden."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
